"""
analyze_path_frequencies.py
---------------------------
Analyzes extracted trajectory paths to identify the most frequent movement patterns
(Origin -> Destination) for each video and model (including Ground Truth).

Features:
- Loads path data generated by `extract_paths.py`.
- Filters out static tracks (where Start Region == End Region).
- Aggregates frequency counts for overall paths and class-specific paths.
- Exports a comprehensive summary CSV suitable for graphing or reporting.
"""

import pandas as pd
import os
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# ==============================================================================
# CONFIGURATION
# ==============================================================================

# Define directories relative to this script
BASE_DIR = Path(__file__).resolve().parent.parent
INPUT_DIR = BASE_DIR / "outputs" / "paths"
OUTPUT_DIR = BASE_DIR / "outputs" / "analysis"

# Ensure output directory exists
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Analysis settings
VIDEOS_TO_ANALYZE = [0, 3]  # 0 corresponds to video0, 3 to video3
MODELS_TO_ANALYZE = ["GT", "NEW", "OLD"]  # Now includes GT


# ==============================================================================
# PATH ANALYZER CLASS
# ==============================================================================

class PathAnalyzer:
    """
    Analyzes trajectory path CSVs to calculate frequency of origin-destination pairs.
    """

    def __init__(self, video_num: int, model: str):
        """
        Initialize the analyzer for a specific video and model version.
        """
        self.video_num = video_num
        self.model = model.upper()
        # Constructs filename like: video0_pathsGT.csv
        self.csv_path = INPUT_DIR / f"video{self.video_num}_paths{self.model}.csv"

    def load_data(self) -> Optional[pd.DataFrame]:
        """
        Loads and validates the path CSV file.
        Returns None if file doesn't exist or is malformed.
        """
        if not self.csv_path.exists():
            print(f"[Warning] File not found: {self.csv_path}")
            return None

        try:
            df = pd.read_csv(self.csv_path)
            required_cols = {'track_id', 'class_name', 'path_step', 'region'}
            if not required_cols.issubset(df.columns):
                print(f"[Error] Missing columns in {self.csv_path.name}. Required: {required_cols}")
                return None
            return df
        except Exception as e:
            print(f"[Error] Failed to read {self.csv_path.name}: {e}")
            return None

    def get_od_pair(self, group: pd.DataFrame) -> Tuple[str, str]:
        """
        Extracts the Start (Origin) and End (Destination) regions from a track.
        Assumes the group is for a single track_id.
        """
        # Ensure sorting by step to correctly identify first and last regions
        group = group.sort_values('path_step')
        
        start_region = group.iloc[0]['region']
        end_region = group.iloc[-1]['region']
        return start_region, end_region

    def run_analysis(self) -> Tuple[Dict[str, int], Dict[str, Dict[str, int]]]:
        """
        Performs the frequency analysis.
        
        Returns:
            Tuple containing:
            - overall_freq: Dict[path_string, count] (All classes combined)
            - class_freq: Dict[class_name, Dict[path_string, count]] (Broken down by class)
        """
        df = self.load_data()
        if df is None or df.empty:
            return {}, {}

        overall_freq = defaultdict(int)
        class_freq = defaultdict(lambda: defaultdict(int))

        # Group by track to reconstruct individual paths
        grouped = df.groupby('track_id')

        for _, group in grouped:
            start, end = self.get_od_pair(group)

            # Filter: Ignore tracks that didn't move between regions (Static)
            # We are interested in traffic flow, not stationary objects.
            if start == end:
                continue

            path_str = f"{start} -> {end}"
            
            # Get class name (handle potential missing values)
            c_name = str(group.iloc[0]['class_name']).replace('"', '').strip()
            if c_name.lower() == 'nan' or not c_name: c_name = "Unknown"

            # Increment counts
            overall_freq[path_str] += 1
            class_freq[c_name][path_str] += 1

        # Sort results by frequency (descending)
        sorted_overall = dict(sorted(overall_freq.items(), key=lambda x: -x[1]))
        
        sorted_class = {}
        for cls, paths in class_freq.items():
            sorted_class[cls] = dict(sorted(paths.items(), key=lambda x: -x[1]))

        return sorted_overall, sorted_class


# ==============================================================================
# MAIN EXECUTION
# ==============================================================================

def main():
    print(f"Starting Path Frequency Analysis...")
    print(f"Reading from: {INPUT_DIR}")
    
    all_results = []

    for video in VIDEOS_TO_ANALYZE:
        for model in MODELS_TO_ANALYZE:
            analyzer = PathAnalyzer(video, model)
            print(f"\n--- Analyzing Video {video} | {model} ---")
            
            overall_paths, per_class_paths = analyzer.run_analysis()

            if not overall_paths:
                print("  No significant paths found or file missing.")
                continue

            # 1. Print Top Summary to Console
            print(f"  Top 5 Frequent Paths:")
            for i, (path, freq) in enumerate(list(overall_paths.items())[:5], 1):
                print(f"    {i}. {path}: {freq}")

            # 2. Collect Data for Export
            # Add Overall entries
            for path, freq in overall_paths.items():
                all_results.append({
                    'video': f'video{video}',
                    'model': model,
                    'class': 'ALL',
                    'path': path,
                    'frequency': freq
                })

            # Add Class-Specific entries
            for cls, paths in per_class_paths.items():
                for path, freq in paths.items():
                    all_results.append({
                        'video': f'video{video}',
                        'model': model,
                        'class': cls,
                        'path': path,
                        'frequency': freq
                    })

    # --- Export Combined Results ---
    if all_results:
        output_file = OUTPUT_DIR / "path_frequency_summary.csv"
        df_results = pd.DataFrame(all_results)
        
        # Sort for better readability: Video -> Model -> Class -> Frequency
        df_results = df_results.sort_values(
            ['video', 'model', 'class', 'frequency'], 
            ascending=[True, True, True, False]
        )
        
        df_results.to_csv(output_file, index=False)
        print(f"\n[Success] Comprehensive summary saved to:\n{output_file}")
        
        # Optional: Print pivot table preview for quick verification
        print("\n--- Summary Pivot (Total Paths per Case) ---")
        pivot = df_results[df_results['class'] == 'ALL'].pivot_table(
            index=['video', 'model'], 
            values='frequency', 
            aggfunc='sum'
        )
        print(pivot)
    else:
        print("\n[Info] No results extracted. Check if input path CSVs exist.")

if __name__ == "__main__":
    main()